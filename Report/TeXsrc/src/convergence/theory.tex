\subsection{Theoretical Results}

\hogwild's original article \cite{2011NRRW} manages to prove that the
asynchronous noise generated by \hogwild, under certain sparsity assumptions of
the $f_i$'s, converged at the same rate as seen in the stochastic gradient
method. However, a newer article from 2015 by De Sa et al. \cite{2015SZOR}
presented a new framework in the context of martingale theory, which drops said
sparsity assumptions and generalizes to certain non-convex formualations. Given
that I just learned about martingale theory essentially two weeks ago in Basic
Probability, and that much of my synthetic tests are on dense datasets, I feel
compelled to present this argument instead. 

The following is a cleaned up summary of the arguments presented in the article,
except I focus on just demonstrating how martingale theory can be used to
generalize convergence arguments for a sequential stochastic gradient method to
the asynchronous case, and cut out the generalization required for the
non-convex situation.

\subsubsection{Initial Machinery}

First, recall the definition of a martingale:
\begin{definition} \label{def:martingale}
  \cite{2004JP} A sequence of random variables $(X_n)_{n \geq 0}$ is called
  a martingale, or an $(\mathcal{F}_n)$-martingale, if
  \begin{enumerate}[(i)]
    \item $\E{|X_n|} < \infty, \forall n$.
    \item $X_n$ is $\mathcal{F}_n$ measurable, $\forall n$.
    \item $\E{X_n \mid \mathcal{F}_m} = X_m$ a.s., $\forall m \leq n$.
  \end{enumerate}
  furthermore a supermartingale (submartingale) is one satisfying (i), (ii)
  exactly, and (iii) with $\leq\ (\geq)$ instead.
\end{definition}
Using this, the idea is to model our convergence with a non-negative
supermartingale $W_t(x_t, \dots, x_0)$ which is a function of the previous
stochastic gradient iterates. These $W_t$, when used in the theory later, will
be associated with specific stochastic algorithms, as an example below we'll see
it applied to serial stochastic gradient. However, given such a supermartingale,
and given a bounded stopping time $B$ (in literature known as a horizon), if our
stochastic gradient iterates are written as $x_{t+1} = x_t - \eta \nabla
f_t(x_t)$, where $\eta$ is the learning rate, and $f_t$ denotes the random
function chosen at time step $t$, then we see that condition (iii) in the above
definition implies that:
\[
  W_{t+1}(x_t - \eta \nabla f_t(x_t), x_t, \dots, x_0)
  \leq
  W_t(x_t, \dots, x_0), \forall t \leq B
\]
which certainly makes sense if our $-\nabla f_t(x_t)$ is a sufficient search
direction. Furthermore, letting our success region be denoted as $S
= B_\e(x^*)$, where $x^*$ is the minimizer of our optimization problem, if we
impose that if $x_t \not\in S, \forall t \leq T$ then:
\[
  W_T(x_T, \dots, x_0) \geq T
\]
then we call $W_t$ a {\it rate supermartingale}. To simplify notation, let $F_t$
be the event where $\nexists t \leq T$ such that $x_t \in S$. 

A good example of the power of this machinery is proving a convergence bound on
the serial version of stochastic gradient: using (iii) of definition
\ref{def:martingale}, one can see that considering $F_T$:
\[
  \E{W_0(x_0)}
  \underbrace{\geq}
  \E{W_T}
  =
  \Prob{F_t}
  \underbrace{\Prob{F_T}\E{W_T | F_T}}_{W_T \geq T} + 
  \underbrace{\Prob{F_T^c}\E{W_T | F_T^c}}_{W_T \geq 0}
  \geq
  \Prob{F_T}T
\]
where the first inequality is by Doob's optional sampling theorem. Thus for
a simple serial stochastic gradient method: $\Prob{F_t} = \E{W_0} / T$.

Now that we can characterize serial stochastic gradient in this model, we need
a method to analyze asynchronous noise. Recall that since we've guaranteed in
the description of \hogwild\ that writes to the iteration variable $x_t$ are
done atomically, the only race condition possible is when updates to entries of
$x_t$ are interleaved with either the other thread's updates or its reads on
$x_t$.

Indeed, when going to update the $i$th component of $x_{t+1}$, the variable used
to compute the gradient may have long since changed, making our iteration look
more like $x_{t+1} = x_t - \nabla f_t(v_t)$ where $v_t$'s entries were the
entries of some previous iterate $x$. Let $\tau_{i,t}$ denote the lag for the
update of the $i$th component of $x_{t+1}$, i.e. $(v_t)_i = ( x_{t-\tau_{i,t}}
)_i$. Then we recognize that this lag for each component $i$ (supposing the
computer hasn't crashed) must be bounded; let $\tau'$ be the the maximum over
$i$ of such bounds and let $\tau = \E{\tau'}$. This is known in literature as
the {\it worst-case expected delay}.

Finally, we need one last definition, mainly one of convinience, to proceed
onward. This describes the main conditions upon a rate supermartingale necessary
to prove that the asynchronous noise error is irrelevant to the convergence
rate.
\begin{definition}
  An algorithm with associated rate supermartingale $W$ is $(H, R, \xi)$-bounded
  if the following conditions hold.
  \begin{enumerate}[(1)]
    \item $W$ must be Lipschitz continuous in the current iterate with parameter
      $H$, i.e.
      \[
        \norm{W_t(u, x_{t-1}, \dots, x_0) - W_t(v, x_{t-1}, \dots, x_0)}
        \leq
        H\norm{u-v}, \forall t, u, v, x_t, \dots, x_0.
      \]
    \item $\nabla f$ must be Lipschitz continuous in expectation with parameter
      $R$, i.e.
      \[
        \E{||\nabla f(x) - \nabla f(y)||} \leq R\norm{u-v}
      \]
    \item The expected magnitude of the update must be bounded by $\xi$, i.e.
      \[
        \E{||\nabla f(x)||} \leq \xi
      \]
  \end{enumerate}
  Note that these look very familiar to the conditions in the stochastic
  gradient method convergence theorem (theorem \ref{thm:sgd}).
\end{definition}

\subsubsection{Convergence of \hogwild}

Finally, now that all of the machinery has been defined, we can get to the main
result:
\begin{theorem} \label{thm:convergence}
  Suppose we have an asynchronous stochastic algorithm with associated rate
  supermartingale $W$ which is $(H,R,\xi)$ bounded with horizon $B$.
  Furthermore, assume that $HR\xi \tau < 1$; then $\forall T \leq B$:
  \[
    \Prob{F_T} \leq \frac{\E{W(0, x_0)}}{(1-HR\xi\tau)T}
  \]
\end{theorem}
Before we prove it, we briefly discuss how to use this theorem in practice.
Suppose we have a loss function $f$ which we want to use \hogwild\ on to
minimize. Then first we need to obtain a rate supermartingale proving the
problem%
\footnote{
  In the article, De Sa et al. describes this as being no more difficult than
  proving serial convergence, but the proof (in the convex case) doesn't seem to
  have any similarity between it and serial convergence, so I can't validate
  this claim.
}, determine $H, R, \xi$ such that $W$ is $(H,R,\xi)$-bounded, and then apply
this theorem to get a proper rate of convergence. This is a very powerful
theorem, as we'll be able to state later, given strongly convex $f$ and with the
other required bounds, we can blanket prove that \hogwild\ works on them.
Furthermore, for nicer non-convex problems, such as the low-rank least-squared
matrix completion problem presented in the paper, it's easy to derive a proper
rate supermartingale as well.

Now, with respect to the proof, we only outline it because it's mainly just
a repeated application of the above bounds we have in order to lower bound away
noise terms, and then it follows the path outlined in the serial stochastic
gradient method proof.
\begin{proof}
  \begin{enumerate}[(i)]
    \item With $W$ defined exactly as in the serial case, it's not a rate
      supermartingale. Instead, from it we construct rate supermartingale $V_t$,
      where $\forall t, x$ where $x_u$ not converged $\forall u < t$:
      \[
        V_t(x_t, \dots, x_0) = W_t(x_t, \dots, x_0) 
        - \underbrace{HR\xi \tau t}_{(1)}
        + \underbrace{
          HR \sum_{k=1}^\infty \norm{x_{t-k+1}-x_{t-k}} \sum_{m=k}^\infty
          \Prob{\tau' \geq m}
        }_{(2)}
      \]
      where (1) allows for longer iteration counts (as HOGWILD needs to allow
      for given noise corruption), and (2) measures distance between recent
      iterates. Otherwise if $x_u$ is converged, then we let $V_t(x_t, \dots,
      x_0) = V_u(x_u, \dots, x_0)$. Basically, we've defined $V$ a stopped
      process.
    \item Show $V_t$ is a rate supermartingale for \hogwild
    \item Using a similar process to the serial stochastic gradient proof, show
      that $\E{V_T} \leq \E{V_0} = \E{W_0}$, then using the law of total
      expectation on this with $F_T$, and recalling that $\E{W_T | F_T} \geq T$,
      we recieve the desired result.
  \end{enumerate}
\end{proof}
Given this, the general theorem for the convex case is:
\begin{theorem} \label{thm:convexconv}
  Consider trying to minimize $f$, which is:
  \begin{itemize}
    \item Strongly convex with parameter $c$.
    \item $\nabla f_k$ Continuously differentiable in $||\cdot||_1$ with
      Lipschitz constant $L$.
    \item Upper bounded second moment of the gradient by $M^2$
    \item Success criteria $\norm{x-x^*}^2 \leq \e$, for some $\e > 0$.
  \end{itemize}
  Then we can construct rate supermartingale $W_t$ such that it's $(H,R,\xi)$
  bounded with $H = 2\sqrt{\e}(2\eta c\e - \eta^2 M^2)^{-1}, R = \eta L,
  \xi = \eta M$. Then choosing step size $\eta$ (for some $\nu \in (0,1)$):
  \[
    \eta = \frac{c\e \nu}{M^2 + 2LM\tau\sqrt{\e}}
  \]
  then we recieve:
  \[
    \Prob{F_T} \leq \frac{M^2 + 2LM\tau\sqrt{\e}}{c^2\e\nu T} \log
    \left(
      e \norm{x_0 -x^*}^2 \e^{-1}
    \right)
  \]
\end{theorem}
